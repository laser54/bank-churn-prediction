{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+CQRcir8T6Z4b0lI6y/Eb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bank Customer Churn â€” Modeling\n",
        "\n",
        "## Purpose of this notebook\n",
        "This notebook focuses on training and evaluating machine learning models\n",
        "for customer churn prediction.\n",
        "\n",
        "The main goals are:\n",
        "- Load preprocessed datasets and artifacts\n",
        "- Train a strong baseline model\n",
        "- Evaluate model performance using appropriate metrics\n",
        "- Establish a reference point for more advanced models\n",
        "\n",
        "All modeling steps rely on artifacts created in `02_preprocessing.ipynb`.\n"
      ],
      "metadata": {
        "id": "jjyIUitnN5vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# System utilities\n",
        "from pathlib import Path\n",
        "\n",
        "# Modeling\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    RocCurveDisplay,\n",
        "    PrecisionRecallDisplay,\n",
        ")\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n"
      ],
      "metadata": {
        "id": "aiBhUq9xN__v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Preprocessing Artifacts\n",
        "\n",
        "In this notebook we load preprocessing outputs generated in\n",
        "`02_preprocessing.ipynb`.\n",
        "\n",
        "Artifacts are expected to be present in the current Colab runtime\n",
        "under the `artifacts/` directory.\n"
      ],
      "metadata": {
        "id": "E5-C0-0COG6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "ARTIFACTS_DIR = Path(\"/content/artifacts\")\n",
        "\n",
        "assert ARTIFACTS_DIR.exists(), (\n",
        "    \"Artifacts directory not found. \"\n",
        "    \"Run 02_preprocessing.ipynb in the same Colab runtime first.\"\n",
        ")\n",
        "\n",
        "print(\"Using artifacts directory:\", ARTIFACTS_DIR.resolve())\n",
        "\n",
        "X_train = pd.read_parquet(ARTIFACTS_DIR / \"X_train.parquet\")\n",
        "X_test  = pd.read_parquet(ARTIFACTS_DIR / \"X_test.parquet\")\n",
        "\n",
        "y_train = pd.read_parquet(ARTIFACTS_DIR / \"y_train.parquet\")[\"churn\"]\n",
        "y_test  = pd.read_parquet(ARTIFACTS_DIR / \"y_test.parquet\")[\"churn\"]\n",
        "\n",
        "X_train.shape, X_test.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "R-1AGwUjOK65",
        "outputId": "378be17e-25cd-4858-eed8-9b4eb38b439b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Artifacts directory not found. Run 02_preprocessing.ipynb in the same Colab runtime first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4284060031.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mARTIFACTS_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/artifacts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m assert ARTIFACTS_DIR.exists(), (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"Artifacts directory not found. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"Run 02_preprocessing.ipynb in the same Colab runtime first.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Artifacts directory not found. Run 02_preprocessing.ipynb in the same Colab runtime first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "X_train = pd.read_parquet(ARTIFACTS_DIR / \"X_train.parquet\")\n",
        "X_test  = pd.read_parquet(ARTIFACTS_DIR / \"X_test.parquet\")\n",
        "\n",
        "y_train = pd.read_parquet(ARTIFACTS_DIR / \"y_train.parquet\")[\"churn\"]\n",
        "y_test  = pd.read_parquet(ARTIFACTS_DIR / \"y_test.parquet\")[\"churn\"]\n",
        "\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "hj8rAsXfRLzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(), y_train.value_counts(normalize=True)\n"
      ],
      "metadata": {
        "id": "tgn-AXGZWn4a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}